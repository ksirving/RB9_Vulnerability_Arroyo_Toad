## predicting distribution

# library(sp)
# library(rgdal)
library(raster)
library(randomForest)
# library(kernlab)
# library(rgl)
# library(ks)
# library(sm)
library(sf)
library(tidyverse)
library(mapview)
# library(caret)
# library(rpart)
library(tidylog)


# upload data -------------------------------------------------------------

## define folders
gridFile <- paste0("ignore/ModelResults/Gridded/")
COMIDFile <- paste0("ignore/ModelResults/COMID/")

## gridded env df with comids
load(file = "ignore/00_RB9_grdded_data.RData") 
head(data_hyd_sf2)

# ## observations
load(file=paste0("ignore/ModelResults/Gridded/Model1/all_presAbs_env_data.RData"))
head(NewDataObsSub)

## get obs and format. makespatial
obs <- NewDataObsSub %>% as.data.frame() %>%
  dplyr::select(PresAbs, cells)
#   
# head(obs)

## upload nhd shape
nhd <- st_read("/Users/katieirving/Library/CloudStorage/OneDrive-SharedLibraries-SCCWRP/SD Hydro Vulnerability Assessment - General/Data/SpatialData/NHD_reaches_RB9_castreamclassification.shp")
## simplify
nhd <- nhd %>%
  st_as_sf %>%
  st_simplify(dTolerance = 0.5, preserveTopology = T)



# Predict on all rb9 region-------------------------------------------------------

#Index refers to the right column of probabilities - in this model the second column, which is probs of "1"
all_data <- na.omit(data_hyd_sf2)
# all_data <- all_data[,c("COMID", sel.vars)] 
head(all_data)
str(all_data)

## empty df for var imp
VarImpx <- NULL

## empty DF for validation
Valsx <- NULL

## define models
models <- paste0("model",seq(1, 10,1))
# m="model2"

## start loop

for(m in models) {
  ## define folder (model) to pull from
  gridFile <- paste0("ignore/ModelResults/Gridded/", m,"/")
  
  ## upload model
  load(file = paste0(gridFile,"rf_model.RData"))
  
  ##  upload presence absence
  load(file=paste0(gridFile, "all_presAbs_env_data.RData"))

 
 ## calculate oob error rate  
  conf <- rf.final$confusion[,-ncol(rf.final$confusion)]
  oob <- 1 - (sum(diag(conf))/sum(conf))
  oob <- oob * 100
  
  ## upload validation data
  load(file=paste0(gridFile, "validation.RData"))
  Vals <- model$results
  Vals <- Vals[1,]
  Vals$Error <- 100-oob
  Vals$TSS <- Vals$Sens + Vals$Spec -1
  Valsx <- rbind(Valsx, Vals)

  ## var imp
  VarImp <- as.data.frame(rf.final$importance) 
  VarImp$Variable <- rownames(VarImp)
  # rownames(VarImp) <- NULL

  VarImpx <- rbind(VarImpx, VarImp)
  
  
  pred <- predict(rf.final, all_data, filename= paste0(gridFile, "SppProbs_no_clim_gridded.img"), type="prob",  index=2, 
                  na.rm=TRUE, overwrite=TRUE, progress="window")
  
  
  pred_df <- as.data.frame(predict(rf.final, all_data, filename= paste0(gridFile, "SppProbs_no_clim_gridded_df.img"), type="prob",  index=2, 
                                   na.rm=TRUE, overwrite=TRUE, progress="window"))
  ## add comids and cells
  pred_df$cells <- all_data$cells
  # pred_df$COMID <- all_data$COMID
  
  
  
  # head(pred_env)
  
  ## get probability, known occs and env data all together - join by cells and comid
  pred_env <- pred_df %>%
    full_join(all_data, by =  c("cells")) %>%
    rename(probOcc = 1) %>%
    # full_join(obs, by = c("cells", "COMID")) %>%
    dplyr::select(probOcc, cells, x, y)

  
  write.csv(pred_env, paste0(gridFile,"probOccs_gridded.csv"))
  
  # head(pred_env)
}


# Combining importance ----------------------------------------------------
head(VarImpx)
library("scales")

range01 <- function(x){(x-min(x))/(max(x)-min(x))}
## get mean and scale and % to make relative
ImpMean <- VarImpx %>% 
  group_by(Variable) %>%
  summarise(MeanImp = mean(MeanDecreaseAccuracy)) %>%
  mutate(MeanImpScaled = rescale(MeanImp)) %>%
  mutate(MeanImpPerc = (MeanImpScaled/sum(MeanImpScaled))*100)

## humanise variables - check the remote senseing
ImpMean <- ImpMean %>%
  mutate(VariableHuman = case_when(Variable == "DS_Mag_50" ~ "Dry Season Baseflow",
                                   Variable == "Peak_10" ~ "Peak Flow: 10-Year Flood",
                                   Variable == "FA_Mag" ~ "Fall Pulse",
                                   Variable == "Peak_2" ~ "Peak Flow: 2-Year Flood",
                                   Variable == "Q99" ~ "Largest Annual Storm",
                                   Variable == "SP_Mag" ~ "Spring Recession",
                                   Variable == "Wet_BFL_Mag_10" ~ "Wet Season Baseflow (Low)",
                                   Variable == "Wet_BFL_Mag_50" ~ "Wet Season Baseflow (Med)",
                                   Variable == "PercentSand" ~ "Sand (%)",
                                   Variable == "PercentClay" ~ "Clay (%)",
                                   Variable == "MRVBF" ~ "MRVBF",
                                   Variable == "AccFlow" ~ "Catchment Area",
                                   Variable == "AWC_r" ~ "Water Storage Capacity",
                                   Variable == "Elev" ~ "Elevation",
                                   Variable == "Slope" ~ "Slope (%)",
                                   Variable == "VRM18" ~ "VRM18",
                                   Variable == "VRM3" ~ "VRM3",
                                   Variable == "TC_042014_RB9.1_Med" ~ "April Brightness (Med)",
                                   Variable == "TC_042014_RB9.2_Med" ~ "April Greenness (Med)",
                                   Variable == "TC_042014_RB9.2_Var" ~ "April Greenness (Var)",
                                   Variable == "TC_042014_RB9.3_Var" ~ "April Wetness (Var)",
                                   Variable == "TC_092014_RB9.1_Var" ~ "Sept. Brightness (Var)",
                                   Variable == "TC_092014_RB9.2_Var" ~ "Sept. Greenness (Var)",
                                   Variable == "TC_092014_RB9.3_Med" ~ "Sept. Wetness (Med)",
                                   Variable == "TC_092014_RB9.3_Var" ~ "Sept. Wetness (Var)"))

## order in increasing values

ImpMean$VariableHuman <- factor(ImpMean$VariableHuman, levels=ImpMean[order(ImpMean$MeanImpPerc,decreasing=F),]$VariableHuman)
ImpMean$VariableHuman

## plot
i1 <- ggplot(ImpMean, aes(x=MeanImpPerc, y=VariableHuman)) +
  geom_point() +
  scale_x_continuous("Relative Importance (%)") +
  scale_y_discrete("") +
  theme_bw()
i1

file.name1 <- "ignore/ModelResults/Gridded/03_relative_importance_mean.jpg"
ggsave(i1, filename=file.name1, dpi=300, height=5, width=8)


# Combining validations  --------------------------------------------------

head(Valsx)
## standard error function
std.error <- function(x) sd(x)/sqrt(length(x))

vdf <- Valsx %>%
  pivot_longer(ROC:TSS, names_to = "Measure", values_to = "Value") %>%
  group_by(Measure) %>%
  summarise(MeanVals = mean(Value), 
            SEVals = std.error(Value),
            SDVals = sd(Value))

vdf

write.csv(vdf, "ignore/ModelResults/Gridded/03_validation_values.csv")

# TSS <-  vdf[] + TNR -1

# Combining probabilities --------------------------------------------------------

## define models
models <- paste0("model",seq(1, 10,1))
# m=2
## empty dataframe
probsx <- NULL

## combine all probabilities
for(m in models) {
  
  ## upload data and format, add model number
  gridFile <- paste0("ignore/ModelResults/Gridded/", m,"/")
  probs <- read.csv(paste0(gridFile,"probOccs_gridded.csv")) %>%
    mutate(Model = m)
  
  ## combine
  probsx <- bind_rows(probsx, probs)

}

### summarise probability over models
probsx_mean <- probsx %>%
 group_by(cells, x, y) %>%
  summarise(MeanProb = mean(na.omit(probOcc)))

head(probsx_mean)

## save out
write.csv(probsx_mean, "ignore/ModelResults/Gridded/03_Av_Probs_Current_RB9.csv")
# probsx_mean <- st_read("ignore/ModelResults/Gridded/03_Av_Probs_Current_RB9.csv")
# Plotting probability of occurrence --------------------------------------

names(probsx_mean)
# sum(is.na(probsx_mean$Latitude))
# ind <- which(is.na(probsx_mean$Latitude))
# probsx_mean[ind,] ### fix these nas, might be the same issue as above, remove for now
# probsx_mean <- na.omit(probsx_mean)

## get mask raster
bmask <- raster("input_data/Elev.tif")

## make probabilities spatial

probs_sf <- probsx_mean %>%
  st_as_sf(coords=c("x", "y"), crs=crs(bmask), remove=F) 

## save out
st_write(probs_sf, "ignore/ModelResults/Gridded/Arroyo_Toad_Prob_Occurrence_RB9.shp", append=F)

probs_sf <- st_read("ignore/ModelResults/Gridded/Arroyo_Toad_Prob_Occurrence_RB9.shp")
## make raster of probs
# str(probsx_mean)
## make spatial and transformCRS
coordinates(probsx_mean) <- ~x+y
projection(probsx_mean) <- "+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs"

## create template raster
# names(bmask) <- "COMID"
x <- bmask

## make rasters of probability in NAD83

  x<-raster::rasterize(probsx_mean, x, field="MeanProb", na.rm =TRUE, sp = TRUE)
  projection(x)<-"+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs"

  ## save
writeRaster(x, "ignore/ModelResults/Gridded/Arroyo_Toad_Prob_Occurrence_RB9.tif", format="GTiff", crs="+proj=geocent +ellps=GRS80 +units=m +no_defs", overwrite=TRUE)
  

## get obs and format. makespatial 
obs <- NewDataObsSub %>% as.data.frame() %>%
  dplyr::select(PresAbs, cells) %>%
  inner_join(probs_sf, by = c("cells")) %>%
  st_as_sf(coords=c("x", "y"), crs=crs(bmask), remove=F) 

## map
library(viridis)

class(probs_sf)
# range(probs_sf$MeanProb)

my_breaks <- c(0, 0.25, 0.5, 0.75, 1)

map1 <- ggplot(data = probs_sf, aes(x = factor(x) ,y= factor(y), fill=MeanProb) ) +
  geom_tile() +
  scale_fill_gradientn(colours=rev(turbo(6)), name="Probability of Occurrence",
                         labels = my_breaks)+
  theme_bw() #+
  # geom_sf(data = subset(obs, PresAbs == 1), shape = 4, size = 2) 


map1

file.name1 <- "ignore/ModelResults/Gridded/03_prob_occs_map_gridded.jpg"
ggsave(map1, filename=file.name1, dpi=300, height=5, width=8)

library(mapview)
library(sf)
library(RColorBrewer)
# webshot::install_phantomjs()

## map
# set background basemaps:
basemapsList <- c("Esri.WorldTopoMap", "Esri.WorldImagery",
                  "Esri.NatGeoWorldMap",
                  "OpenTopoMap", "OpenStreetMap", 
                  "CartoDB.Positron", "Stamen.TopOSMFeatures")

mapviewOptions(basemaps=basemapsList, vector.palette = colorRampPalette(c(  "red", "green")) , fgb = FALSE)


m1 <- mapview(probs_sf, zcol = "MeanProb",  cex = 3, legend = TRUE, layer.name = "Probability of Occurrence") #+
  # mapview(subset(obs, PresAbs == 1), col.regions = "black",cex = 2.5, layer.name = "Observations")

m1@map %>% leaflet::addMeasure(primaryLengthUnit = "meters")

mapshot(m1, url = paste0(getwd(), "/ignore/ModelResults/Gridded/Arroyo_Toad_Prob_Occurrence_RB9.html"),
        file = paste0(getwd(), "/ignore/ModelResults/Gridded/Arroyo_Toad_Prob_Occurrence_RB9.png"))
getwd()

# set background basemaps:
basemapsList <- c("Esri.WorldTopoMap", "Esri.WorldImagery",
                  "Esri.NatGeoWorldMap",
                  "OpenTopoMap", "OpenStreetMap", 
                  "CartoDB.Positron", "Stamen.TopOSMFeatures")

mapviewOptions(basemaps=basemapsList, vector.palette = colorRampPalette(c(  "red", "green")) , fgb = FALSE)


m1 <- #mapview(probs_sf, zcol = "MeanProb",  cex = 3, legend = TRUE, layer.name = "Probability of Occurrence") #+
mapview(subset(obs, PresAbs == 1), col.regions = "black",cex = 2.5, layer.name = "Observations")

m1@map %>% leaflet::addMeasure(primaryLengthUnit = "meters")

mapshot(m1, url = paste0(getwd(), "/ignore/ModelResults/Gridded/Arroyo_Toad_Observations.html"),
        file = paste0(getwd(), "/ignore/ModelResults/Gridded/Arroyo_Toad_Observations.png"))
getwd()



